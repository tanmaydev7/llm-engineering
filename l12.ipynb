{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca015497",
   "metadata": {},
   "source": [
    "# RAG Continued.\n",
    "\n",
    "## Expert Question Answerer for InsureLLM\n",
    "LangChain 1.0 implementation of a RAG pipeline.\n",
    "\n",
    "Using the VectorStore we created last time (with HuggingFace all-MiniLM-L6-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80614bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09653537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-oss:120b\"\n",
    "DB_NAME = \"vector_db\"\n",
    "load_dotenv(override=True)\n",
    "OLLAMA_API_KEY = os.getenv('OLLAMA_API_KEY')\n",
    "if not OLLAMA_API_KEY:\n",
    "    raise Exception('Missing api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec63ae",
   "metadata": {},
   "source": [
    "## Connect to Chroma; use Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6141760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma(persist_directory=DB_NAME, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b990ba3",
   "metadata": {},
   "source": [
    "### Set up the 2 key LangChain objects: retriever and llm\n",
    "\n",
    "#### A sidebar on \"temperature\":\n",
    "- Controls how diverse the output is\n",
    "- A temperature of 0 means that the output should be predictable\n",
    "- Higher temperature for more variety in answers\n",
    "\n",
    "Some people describe temperature as being like 'creativity' but that's not quite right\n",
    "- It actually controls which tokens get selected during inference\n",
    "- temperature=0 means: always select the token with highest probability\n",
    "- temperature=1 usually means: a token with 10% probability should be picked 10% of the time\n",
    "\n",
    "Note: a temperature of 0 doesn't mean outputs will always be reproducible.(Even then, it's not always reproducible.)\n",
    "\n",
    "Note 2: if you want creativity, use the System Prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f6023c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatOllama(\n",
    "    temperature=0,\n",
    "    model=MODEL,\n",
    "    base_url=\"https://ollama.com\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee07619",
   "metadata": {},
   "source": [
    "### These LangChain objects implement the method `invoke()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9598ce65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9d40dc7f-98bb-4ab4-9652-854165b1ae12', metadata={'source': 'knowledge-base\\\\employees\\\\Alex Thomson.md', 'doc_type': 'employees'}, page_content='## Other HR Notes\\n- Alex Thomson is an active member of the Diversity and Inclusion committee at Insurellm and has participated in various community outreach programs.  \\n- Alex has received external training on advanced CRM usage, which has subsequently improved team efficiency and productivity.\\n- Continuous professional development through attending sales conventions and workshops, with plans to pursue certification in Sales Enablement in 2024.\\n- Recognized by peers for promoting a supportive and high-energy team environment, often organizing team-building activities to enhance camaraderie within the SDR department. \\n\\n--- \\n**Comment:** Alex Thomson is considered a cornerstone of Insurellm’s sales team and has a bright future within the organization.'),\n",
       " Document(id='a0f62600-f1bf-4b4d-b33a-85e1cc6e39ef', metadata={'source': 'knowledge-base\\\\employees\\\\Alex Chen.md', 'doc_type': 'employees'}, page_content='Alex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.'),\n",
       " Document(id='aff266a9-fc1a-48ae-9d26-4f198e4f8fde', metadata={'doc_type': 'employees', 'source': 'knowledge-base\\\\employees\\\\Alex Thomson.md'}, page_content=\"# HR Record\\n\\n# Alex Thomson\\n\\n## Summary\\n- **Date of Birth:** March 15, 1995\\n- **Job Title:** Sales Development Representative (SDR)\\n- **Location:** Austin, Texas\\n- **Current Salary:** $65,000  \\n\\n## Insurellm Career Progression\\n- **November 2022** - Joined Insurellm as a Sales Development Representative. Alex Thomson quickly adapted to the team, demonstrating exceptional communication and rapport-building skills.\\n- **January 2023** - Promoted to Team Lead for special projects due to Alex's initiative in driving B2B customer outreach programs.  \\n- **August 2023** - Developed a training module for new SDRs at Insurellm, enhancing onboarding processes based on feedback and strategies that Alex Thomson pioneered.  \\n- **Current** - Continues to excel in the role, leading a small team of 5 SDRs while collaborating closely with the marketing department to identify new lead-generation strategies.\"),\n",
       " Document(id='72796c87-ccc5-4e86-8171-81fdcc087f5c', metadata={'doc_type': 'employees', 'source': 'knowledge-base\\\\employees\\\\Alex Harper.md'}, page_content='- **2022**:  \\n  - **Base Salary**: $65,000 (Promotion to Senior SDR)  \\n  - **Bonus**: $13,000 (20% of base due to performance)  \\n\\n- **2023**:  \\n  - **Base Salary**: $75,000  \\n  - **Bonus**: $15,000 (20% of base)  \\n\\n## Other HR Notes  \\n- **Training Completed**:  \\n  - CRM Analytics & Data Management Workshop (2021)  \\n  - Leadership Training Program (2022)  \\n  - Advanced Sales Negotiation Course (2023)  \\n\\n- **Awards**:  \\n  - Insurellm \"SDR of the Year\" Award (2022)  \\n  - Monthly MVP Recognition (3 times in 2023)  \\n\\n- **Interests**:  \\n  - In Alex\\'s spare time, they enjoy participating in community volunteer programs, particularly those focused on financial literacy.  \\n  - Alex is also an avid runner and has participated in several charity marathons.  \\n\\n- **Feedback from HR**:  \\n  - Alex Harper is noted for their work ethic, positive attitude, and willingness to go above and beyond for both clients and colleagues. Recognized for fostering a team spirit within the SDR team.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Who is Alex?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b3695eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I’m not sure which “Alex” you’re referring to—there are lots of well‑known people, fictional characters, and personal acquaintances with that name. Could you give me a bit more context? For example, are you thinking of:\\n\\n* A public figure (e.g., Alex Trebek, Alex Rodriguez, Alex Morgan, etc.)  \\n* A character from a book, TV show, or movie (e.g., Alex DeLarge from *A Clockwork Orange*, Alex Danvers from *Supergirl*, etc.)  \\n* Someone you know personally or a colleague  \\n\\nLet me know, and I’ll be happy to give you the information you’re looking for!', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b', 'created_at': '2025-12-14T16:05:00.84605426Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2092342157, 'load_duration': None, 'prompt_eval_count': 71, 'prompt_eval_duration': None, 'eval_count': 237, 'eval_duration': None, 'model_name': 'gpt-oss:120b', 'model_provider': 'ollama'}, id='lc_run--019b1d9b-a340-7aa2-96d8-1e997e4f323c-0', usage_metadata={'input_tokens': 71, 'output_tokens': 237, 'total_tokens': 308})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who is Alex?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054b223",
   "metadata": {},
   "source": [
    "## Time to put this together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6525ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a knowledgeable, friendly assistant representing the company Insurellm.\n",
    "You are chatting with a user about Insurellm.\n",
    "If relevant, use the given context to answer any question.\n",
    "If you don't know the answer, say so.\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d99291cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history):\n",
    "    # retrieve the relevant info from vector db\n",
    "    docs = retriever.invoke(question)\n",
    "    # prepare context based on retrieved docs\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c178a710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Alex Thomson** is one of Insurellm’s standout team members:\\n\\n| Detail | Information |\\n|--------|--------------|\\n| **Full Name** | Alex Thomson |\\n| **Job Title** | Sales Development Representative (SDR) – currently also a Team Lead for a small group of 5 SDRs |\\n| **Location** | Austin, Texas |\\n| **Date of Birth** | March\\u202f15\\u202f1995 |\\n| **Current Salary** | $65,000 base (plus performance bonuses) |\\n| **Career Highlights at Insurellm** | • Joined the company in\\u202fNov\\u202f2022 as an SDR<br>• Promoted to Team Lead for special projects in\\u202fJan\\u202f2023<br>• Created a training module for new SDRs in\\u202fAug\\u202f2023<br>• Consistently collaborates with Marketing to develop new lead‑generation strategies |\\n| **Compensation History** | 2022 – $65\\u202fk base + $13\\u202fk bonus (20% of base)<br>2023 – $75\\u202fk base + $15\\u202fk bonus (20% of base) |\\n| **Key Awards & Recognitions** | • “SDR of the Year” (2022)<br>• Monthly MVP (3 times in 2023) |\\n| **Professional Development** | Trained in CRM Analytics & Data Management, Leadership, Advanced Sales Negotiation; active on the Diversity & Inclusion committee; plans to earn a Sales Enablement certification in\\u202f2024 |\\n| **Personal Interests** | Community volunteer work (especially financial‑literacy programs), charity marathons, running |\\n| **Peer Feedback** | Known for a high‑energy, supportive attitude, strong work ethic, and a knack for fostering team spirit. |\\n\\nIn short, Alex Thomson is considered a cornerstone of Insurellm’s sales organization—someone who drives results, mentors teammates, and contributes actively to both the company’s growth and its community initiatives.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is Alex?\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a42b4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\dev\\llm-engineering\\llm-test\\Lib\\site-packages\\gradio\\chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(answer_question).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
